---
title: "Assignment 1"
output: html_notebook
---

First things first, load the libraries we need for the analysis.
```{r}
library(tidyverse)
library(lubridate)
library(factoextra)
```

# Importing and cleaning data
Let's start by importing the raw data into R.

```{r}
#cities <- read_csv("data/cities_df.csv")
#trips <- read_csv("data/trips_df.csv")
#people <- read_tsv("data/people_df.tsv")
#people_work <- read_tsv("data/people_work.tsv")
cities <- fread("data/cities_df.csv", header = TRUE, check.names = TRUE, data.table = FALSE)
trips <- fread("data/trips_df.csv", header = TRUE, check.names = TRUE, data.table = FALSE)
```

## City data
First, we'll have a look at the data we got for the cities.

```{r}
cities %>% head()
```

The column names are capitalized. Let's convert them to all lowercase to make it easier to work with. 

```{r}
colnames(cities) <- tolower(colnames(cities))
cities <- cities[,!duplicated(colnames(cities))]
```

That's better. By doing `duplicated(cities$place_slug)`, we see that there's no duplicates of any of the cities, so removing duplicates is unnecessary.
The  `read_tsv` function created a new column with some rownames for us, in this case the X1 column with values ranging from 1-731. It would however make more sense to make the place_slug our rowname, since that indicates which city each row is representing. Let's do that.

```{r}
rownames(cities) <- cities[,"place_slug"]
```


Let's convert the ratings to factors, thus enabling sorting of these. I am manually setting the factor levels such that it is correcly sorted from bad to great.

```{r}
factor_levels <- c("bad", "okay", "good", "great")
cities <- cities %>% mutate(a.c.or.heating = factor(a.c.or.heating, levels = factor_levels),
                            adult.nightlife = factor(adult.nightlife, levels = factor_levels),
                            air.quality = factor(air.quality, levels = factor_levels),
                            cost.of.living = factor(cost.of.living, levels = factor_levels),
                            english.speaking = factor(english.speaking, levels = factor_levels),
                            female.friendly = factor(female.friendly, levels = factor_levels),
                            free.wifi.in.city = factor(free.wifi.in.city, levels = factor_levels),
                            freedom.of.speech = factor(freedom.of.speech, levels = factor_levels),
                            friendly.to.foreigners = factor(friendly.to.foreigners, levels = factor_levels),
                            fun = factor(fun, levels = factor_levels),
                            happiness = factor(happiness, levels = factor_levels),
                            healthcare = factor(healthcare, levels = factor_levels),
                            lgbt.friendly = factor(lgbt.friendly, levels = factor_levels),
                            nightlife = factor(nightlife, levels = factor_levels),
                            peace = factor(peace, levels = factor_levels),
                            places.to.work.from = factor(places.to.work.from, levels = factor_levels),
                            quality.of.life = factor(quality.of.life, levels = factor_levels),
                            racial.tolerance = factor(racial.tolerance, levels = factor_levels),
                            safety = factor(safety, levels = factor_levels),
                            startup.score = factor(startup.score, levels = factor_levels),
                            traffic.safety = factor(traffic.safety, levels = factor_levels),
                            walkability = factor(walkability, levels = factor_levels))
```

I am also going to convert the Average trip length to a numeric value by first removing the "days" part from the variable using a regular expression, and then converting the resulting string to a numeric value. This enables us to do some analysis with it.

```{r}
cities <- cities %>% mutate(avg.trip.length = as.numeric(str_extract(avg.trip.length, "[0-9]+")))
```

Let's also convert the population and internet speed to a numeric value, more specifically a double like the above. The regular expression below takes everything that isn't a numeric value and replaces it with nothing.

```{r}
cities <- cities %>% mutate(population = as.numeric(gsub("[^0-9+]", "", population)),
                            internet.speed = as.numeric(gsub("[^0-9+]", "", internet.speed)))
head(cities$population)
```

Let's use the same trick for other numeric values that we want to use later. Here, I use a regular expression to get the first number after the dollar-sign, and then remove the dollar-sign afterwards. 

```{r}
cities <- cities %>% mutate(beer = as.numeric(gsub("\\$", "", str_extract(beer, "\\$[0-9,.]+"))),
                            airbnb = as.numeric(gsub("\\$", "", str_extract(airbnb, "\\$[0-9,.]+"))),
                            coffee = as.numeric(gsub("\\$", "", str_extract(coffee, "\\$[0-9,.]+"))),
                            hotel = as.numeric(gsub("\\$", "", str_extract(hotel, "\\$[0-9,.]+"))))
head(cities)
```


## Trip data

First up, let's have a look at the trip data.

```{r}
trips %>% head()
```

As we can see, the trip data has the same place_slug and country_slug column as the cities data. This makes for a great key when we are joining our data. Great!

Since the date_end and date_start columns contain dates, let's convert them to a date datatype.

```{r}
trips <- trips %>% drop_na(date_end, date_start) %>% mutate(date_end = ymd(date_end), date_start = ymd(date_start))
trips <- trips %>% drop_na(date_end, date_start)
```

After the conversion, I drop all NA's from the two columns. This is because some of the dates failed to parse.

## People data

```{r}
people_work %>% head()
```

# Joining and Exploring the data

## Trip lengths

The city data has lots of useful information, among this the average trip length. In my data cleanup, I converted this to a numeric value to enable analysis such as the following. 

Everyone loves a drink or two, but is that also reflected in the average trip length to the different cities? Let's find out by grouping the data by the nightlife factor and getting the mean of the average trip lengths.

```{r}
fun_avg_trip <- cities %>% group_by(adult.nightlife) %>% filter(!is.na(avg.trip.length), !is.na(adult.nightlife)) %>% summarise(mean = mean(avg.trip.length))
ggplot(fun_avg_trip, aes(x = adult.nightlife, y = mean)) + geom_bar(stat = "identity")
```

It seems that is indeed the case!

## Think of the environment!

I wonder how the air quality differs across regions. To do this, I first group the data by air quality and region, and then use the `tally()` function to count the number of occurances of quality for each region. Lastly, I add the column `scale`, which is the scaled count to more correctly represent the data. I do this since there are many more cities in some regions than others.

I then generate a plot of the results, using `position = "dodge"` to have the bars grouped together instead of overlapping.

```{r}
region.air.quality <- cities %>% group_by(air.quality, region) %>% drop_na() %>% tally() %>% mutate(scale = scale(n, center = FALSE))
ggplot(region.air.quality, aes(fill = region, x = air.quality, y = scale)) + geom_bar(position = "dodge", stat = "identity")
```

As expected, the air quality in the asian countries is generally worse. The air quality in Europe is very good overall, with the Americas coming in second.

## Adult nightlife, happiness, fun and beer prices!

I wonder if there's any patterns between the adult nightlife, happiness, fun and beer prices in different countries. One would think so!

First off, I select only the data I am interested in exploring, and then convert the factors to numeric values so they are workable. I also remove any NA's and duplicate rows.

```{r}
cities.clustering <- cities %>% select(adult.nightlife, happiness, fun, beer, place_slug, country)
cities.clustering <- cities.clustering %>% mutate(adult.nightlife = as.numeric(adult.nightlife),
                                                  happiness = as.numeric(happiness),
                                                  fun = as.numeric(fun))
cities.clustering <- cities.clustering %>% drop_na()
cities.clustering <- cities.clustering %>% distinct(country, .keep_all = TRUE)
```

Using the so called Elbow method, we'll try to determine the optimal number of clusters for our clustering.

```{r}
fviz_nbclust(scale(cities.clustering %>% select(-place_slug, -country)), kmeans, method = "wss")
```

Since the peak starts at 4-6, I will make a desicion and go with 6 as my k.

Next, I set the rownames since fviz uses those for visualization. I then create a K-Means cluster, making sure to scale it to account for different observation counts in the data (for comparabilitys sake).

```{r}
rownames(cities.clustering) <- cities.clustering %>% pull(country)
km.cities.clustering <- kmeans(cities.clustering %>% select(-place_slug, -country) %>% scale(), centers = 6)
fviz_cluster(km.cities.clustering, data = cities.clustering %>% select(-place_slug, -country) %>% scale())
```

This doesn't tell us much, but we can see that the results are very clustered, so no real spread. We also see that there's a clear outlier in South Korea, where beer is very expensive. Let's take a closer look at the data.

```{r}
cities.clustering %>% bind_cols(cluster = km.cities.clustering$cluster) %>% select(-place_slug, -country) %>% group_by(cluster) %>% mutate(n = n()) %>% summarise_all(funs(mean))
```

Interestingly, the 2nd cluster has the second highest beer prices, but also scores relatively high in all other parameters. Maybe expensive beer is better after all?

By joining our clustered dataframe with the trips data, we can see how many people visited the countries in the different clusters. First up, we left join the trips with the cities data, meaning that we take everything in the trips data where `place_slug` matches the `place_slug` in the clustered cities data.

```{r}
cities.clustering <- cities.clustering %>% bind_cols(cluster = km.cities.clustering$cluster)
trips.clustering <- trips %>% left_join(cities.clustering %>% select(place_slug, cluster), by = "place_slug")
```

Let's group the trips by cluster, and count the number of rows.

```{r}
trips.clustering %>% group_by(cluster) %>% count()
```

Alright, a lot of people visited the second cluster. My assumption is that the second cluster consists of primarely European countries. Let's check if that is correct.

```{r}
cities.clustering.region <- cities %>% left_join(cities.clustering %>% select(place_slug, cluster), by = "place_slug")
cities.clustering.region %>% group_by(cluster, region) %>% summarise(count = n())
```

Alright, seems like that was indeed the case. However, there were also countries from Latin America and the Middle East. Interesting.

Please not that the above could have been also accomplished without using join, by simply including the region when we created the clustering. However, this nicely demonstrates what joins can do.

## Internet speed and programmers